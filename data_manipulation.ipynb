{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data into dataframe\n",
    "df = pd.read_csv(\"emissions.csv\", header=0)\n",
    "loan_df = pd.read_csv(\"train_loan.csv\", header=0)\n",
    "test_df = pd.read_csv(\"test.csv\", header=0)\n",
    "train_df = pd.read_csv(\"train.csv\", header=0)\n",
    "\n",
    "loan_df2 = loan_df.copy()\n",
    "\n",
    "## read from excel sheets\n",
    "#xl = pd.ExcelFile('filename.xls')\n",
    "#print xl.sheet_names\n",
    "\n",
    "#df7 = xl.parse('sheet1')\n",
    "#df8 = xl.parse('sheet2')\n",
    "#df9 = xl.parse('sheet3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to file\n",
    "#df.to_csv('foo.csv')\n",
    "#df.to_excel('foo.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic information\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of observation for each parameters\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print type of each variables\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accessing element\n",
    "df.iloc[1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accessing rows\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accessing columns\n",
    "df['noise_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find maximum\n",
    "df['noise_level'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find minimum\n",
    "df['noise_level'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find index of maximum\n",
    "df['noise_level'].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find index of minimum\n",
    "df['noise_level'].argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a. Filter information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter in a column\n",
    "df.manufacturer[df['manufacturer'] == 'Lamborghini']\n",
    "df['noise_level'][df['noise_level'] < 60]\n",
    "df['model'][df['extra_urban_metric'] > 30]\n",
    "df['extra_urban_metric'][(df['extra_urban_metric'] < 30) & (df['model'] == 'Omega - Model Year 2003')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter column by string which contains the word 'sunroof'\n",
    "df[df['description'].str.contains('sunroof')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter by observations\n",
    "df[df['year'].isin([2005, 2008])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return column without the NaN observations\n",
    "df['thc_nox_emissions'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find number of null values in a column\n",
    "df['thc_nox_emissions'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same\n",
    "len(df['thc_nox_emissions'][df['thc_nox_emissions'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find number of null values in the data\n",
    "df.apply(lambda x: sum(x.isnull()),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b. Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# most common value (mode)\n",
    "df['manufacturer'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mean value\n",
    "df['engine_capacity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# median\n",
    "df['engine_capacity'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# unique values\n",
    "df['manufacturer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count number of observations\n",
    "df['manufacturer'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count number of observations of each type (frequency table) (same as histogram)\n",
    "df['manufacturer'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "df['noise_level'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot box plot\n",
    "df.boxplot(column='noise_level', return_type='axes')\n",
    "plt.show()\n",
    "df.boxplot(column='noise_level', by = 'manufacturer')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x = loan_df['Education'], y = loan_df['ApplicantIncome'], hue = loan_df['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify outlier data (filter) thanks to the histogram above\n",
    "df['noise_level'][df['noise_level'] < 60]\n",
    "\n",
    "# remove outlier data\n",
    "df = df[df['noise_level'] > 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.c. Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot scatter plot\n",
    "plt.scatter(df['urban_metric'], df['extra_urban_metric'])\n",
    "plt.xlabel('Urban metric')\n",
    "plt.ylabel('Extra urban metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute mean value of noise level for each manufacturer and sort them in ascending order\n",
    "df.pivot_table(values='noise_level', index=['manufacturer'], aggfunc=lambda x: x.mean()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same using groupby\n",
    "grouped_data = df.groupby('manufacturer')\n",
    "grouped_data['noise_level'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# groupby\n",
    "df10 = df.copy()\n",
    "df10.groupby(['manufacturer', 'year']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pivot table\n",
    "pd.pivot_table(df10, values='noise_level', index=['manufacturer', 'year'], columns=['transmission_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter\n",
    "# grouped_data.get_group('Lamborghini')['noise_level']\n",
    "# same as\n",
    "# df.noise_level[df['manufacturer'] == 'Lamborghini']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# relationship between 2 numerical variables\n",
    "grouped_data = df.groupby('year')\n",
    "grouped_data['noise_level'].mean().plot()\n",
    "plt.ylabel('average noise level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.d. Reorganise data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate columns into a new dataframe\n",
    "df2 = pd.concat([df['urban_metric'], df['extra_urban_metric'], df['combined_metric']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge 2 dataframe according to one common column\n",
    "# data_df = pd.merge(data_df, articles_df, on='reference_article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort by noise level\n",
    "df.sort_values(by='noise_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create list of header labels\n",
    "train_header = list(train_df.columns.values)\n",
    "train_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy data frame\n",
    "df10 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert dataframe to numpy array\n",
    "data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# applymap: for loop for the whole data frame\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def convert(grade):\n",
    "    if grade >= 90 and grade <= 100:\n",
    "        x = 'A'\n",
    "    elif grade >= 80 and grade <= 89:\n",
    "        x = 'B'\n",
    "    elif grade >= 70 and grade <= 79:\n",
    "        x = 'C'\n",
    "    elif grade >= 60 and grade <= 69:\n",
    "        x = 'D'\n",
    "    elif grade >= 0 and grade <= 59:\n",
    "        x = 'F'\n",
    "\n",
    "    return x\n",
    "\n",
    "grades_df.applymap(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply: for loop for a data frame column (or pandas series)\n",
    "\n",
    "names = pd.Series([\n",
    "    'Andre Agassi',\n",
    "    'Barry Bonds',\n",
    "    'Christopher Columbus',\n",
    "    'Daniel Defoe',\n",
    "    'Emilio Estevez',\n",
    "    'Fred Flintstone',\n",
    "    'Greta Garbo',\n",
    "    'Humbert Humbert',\n",
    "    'Ivan Ilych',\n",
    "    'James Joyce',\n",
    "    'Keira Knightley',\n",
    "    'Lois Lane',\n",
    "    'Mike Myers',\n",
    "    'Nick Nolte',\n",
    "    'Ozzy Osbourne',\n",
    "    'Pablo Picasso',\n",
    "    'Quirinus Quirrell',\n",
    "    'Rachael Ray',\n",
    "    'Susan Sarandon',\n",
    "    'Tina Turner',\n",
    "    'Ugueth Urbina',\n",
    "    'Vince Vaughn',\n",
    "    'Woodrow Wilson',\n",
    "    'Yoji Yamada',\n",
    "    'Zinedine Zidane'\n",
    "])\n",
    "\n",
    "\n",
    "def reverse_name(name):\n",
    "        split_name = name.split()\n",
    "        return split_name[1]+', '+split_name[0]\n",
    "        \n",
    "names.apply(reverse_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize column\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def standardise_column(column):\n",
    "    return (column - column.mean()) / column.std(ddof=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a. Format information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format date\n",
    "def format_date(int_date):\n",
    "    \"\"\" convert integer date yyyymmdd to datetime object \"\"\"\n",
    "    # convert to string\n",
    "    date = str(int_date)\n",
    "\n",
    "    return dt.strptime(date, '%Y%m%d')    \n",
    "    \n",
    "#df7['date'] = data_df['date'].apply(format_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert string to lower case\n",
    "df['manufacturer'] = df['manufacturer'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map string to integer\n",
    "Ports = list(enumerate(np.unique(train_df['Embarked'])))    # determine all values of Embarked,\n",
    "Ports_dict = {name : i for i, name in Ports}              # set up a dictionary in the form  Ports : index\n",
    "train_df['Embarked'] = train_df['Embarked'].map( lambda x: Ports_dict[x]).astype(int)     # Convert all Embark strings to int\n",
    "\n",
    "train_df['Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map string into integer\n",
    "var_mod = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    loan_df[i] = le.fit_transform(loan_df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_data(df, column, mapping):\n",
    "    \"\"\"\n",
    "    map column in dataframe\n",
    "    \"\"\"\n",
    "    df[column] = df[column].map(mapping).dropna().astype(int)\n",
    "    \n",
    "map_gender = {'Male':1, 'Female':0}    \n",
    "map_data(loan_df, 'Gender', map_gender)\n",
    "\n",
    "\n",
    "# same as\n",
    "#def coding(col, codeDict):\n",
    "#  colCoded = pd.Series(col, copy=True)\n",
    "#  for key, value in codeDict.items():\n",
    "#        colCoded.replace(key, value, inplace=True)\n",
    "#  return colCoded\n",
    "\n",
    "# loan_df['Gender_coded'] = coding(loan_df['Gender'], {'N':0,'Y':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Binning:\n",
    "def binning(col, cut_points, labels=None):\n",
    "    #Define min and max values:\n",
    "    minval = col.min()\n",
    "    maxval = col.max()\n",
    "\n",
    "    #create list by adding min and max to cut_points\n",
    "    break_points = [minval] + cut_points + [maxval]\n",
    "\n",
    "    #if no labels provided, use default labels 0 ... (n-1)\n",
    "    if not labels:\n",
    "        labels = range(len(cut_points)+1)\n",
    "\n",
    "    #Binning using cut function of pandas\n",
    "    colBin = pd.cut(col,bins=break_points,labels=labels,include_lowest=True)\n",
    "    return colBin\n",
    "\n",
    "# Binning age:\n",
    "cut_points = [90,140,190]\n",
    "labels = [\"low\",\"medium\",\"high\",\"very high\"]\n",
    "loan_df[\"LoanAmount_Bin\"] = binning(loan_df[\"LoanAmount\"], cut_points, labels)\n",
    "print pd.value_counts(loan_df[\"LoanAmount_Bin\"], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.b. Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "# df7.drop_duplicates(subset=['column_name'], keep='last', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop un-insightful columns\n",
    "df = df.drop(['file', 'particulates_emissions'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove null observations in dataframe\n",
    "df[df['thc_nox_emissions'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c. Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "df3 = df.copy()\n",
    "df3.fillna(value=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill by median of a group\n",
    "\n",
    "# map gender\n",
    "train_df['Gender'] = train_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# create a reference table with the medians by gender and class\n",
    "median_ages = np.zeros((2,3))\n",
    "\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages[i,j] = train_df[(train_df['Gender'] == i) & (train_df['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "        \n",
    "# create a extra column\n",
    "train_df['AgeFill'] = train_df['Age']      \n",
    "\n",
    "# fill it with the median ages\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        train_df.loc[ (train_df.Age.isnull()) & (train_df.Gender == i) & (train_df.Pclass == j+1),'AgeFill'] = median_ages[i,j] \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same\n",
    "if len(test_df.Fare[ test_df.Fare.isnull() ]) > 0:\n",
    "    median_fare = np.zeros(3)\n",
    "    for f in range(0,3):                                             \n",
    "        median_fare[f] = test_df[ test_df.Pclass == f+1 ]['Fare'].dropna().median()\n",
    "    for f in range(0,3):                                              \n",
    "        test_df.loc[ (test_df.Fare.isnull()) & (test_df.Pclass == f+1 ), 'Fare'] = median_fare[f]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# same as above: fill by median of group self-employed and education\n",
    "\n",
    "# remove missing values in subgroups\n",
    "loan_df2['Self_Employed'].fillna('No',inplace=True)\n",
    "\n",
    "#create pivot table\n",
    "table = loan_df2.pivot_table(values='LoanAmount', index='Self_Employed', columns='Education', aggfunc=np.median)\n",
    "\n",
    "# Define function to return value of this pivot_table\n",
    "def fage(x):\n",
    "    return table.loc[x['Self_Employed'], x['Education']]\n",
    "\n",
    "# Replace missing values\n",
    "loan_df2['LoanAmount'].fillna(loan_df2[loan_df2['LoanAmount'].isnull()].apply(fage, axis=1), inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_most_common(df, column):\n",
    "    \"\"\"\n",
    "    fill NaN values in column in df by the most common entry\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(df[column][df[column].isnull()]) > 0:    \n",
    "        df[column][df[column].isnull()] = df[column].dropna().mode().values    \n",
    "\n",
    "    # equivalent to\n",
    "#    df[column].fillna(df[column].dropna().mode()[0], inplace=True)\n",
    "\n",
    "fill_most_common(train_df, 'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_mean(df, column):    \n",
    "    \"\"\"\n",
    "    fill NaN values in column in df by the mean of the column\n",
    "    \"\"\"   \n",
    "\n",
    "    mean_value = df[column].dropna().mean()\n",
    "\n",
    "    if len(df[column][df[column].isnull()]) > 0:\n",
    "        df.loc[(df[column].isnull()), column] = mean_value\n",
    "        \n",
    "    # equivalent to \n",
    "#    df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "fill_mean(loan_df, 'LoanAmount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.d. Deal with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete outliers using a log transform\n",
    "loan_df['LoanAmount_log'] = np.log(loan_df['LoanAmount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
